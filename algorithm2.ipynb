{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/lawgot/.venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The context does not provide information about the labor law.\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import textwrap\n",
    "from langchain.vectorstores import Chroma\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import torch\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pickle\n",
    "\n",
    "# Define the Document class\n",
    "class Document:\n",
    "    def __init__(self, page_content, metadata=None):\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata\n",
    "\n",
    "# Open the PDF file\n",
    "with open(\"./ipc-data.pdf\", \"rb\") as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    document = reader.pages[0].extract_text()\n",
    "\n",
    "# Initialize a text splitter to split documents into smaller chunks\n",
    "chunk_size = 500\n",
    "texts = textwrap.wrap(document, chunk_size)\n",
    "\n",
    "# Create a list of Document objects\n",
    "documents = [Document(text) for text in texts]\n",
    "\n",
    "# Define the embeddings\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"multi-qa-mpnet-base-dot-v1\")\n",
    "\n",
    "# Create a Chroma vector database from the documents\n",
    "db = Chroma.from_documents(documents, embeddings, persist_directory='./persist_directory/')\n",
    "\n",
    "# Specify the checkpoint for the language model\n",
    "checkpoint = \"MBZUAI/LaMini-Flan-T5-783M\"\n",
    "\n",
    "# Initialize the tokenizer and base model for text generation\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, torch_dtype=torch.float32)\n",
    "\n",
    "# Specify the device for the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "# Create a text generation pipeline\n",
    "pipe = pipeline(\n",
    "    'text2text-generation',\n",
    "    model=base_model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    "    do_sample=True,\n",
    "    temperature=0.3,\n",
    "    top_p=0.95\n",
    ")\n",
    "\n",
    "# Initialize a local language model pipeline\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# Create a RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=local_llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2}),\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "# Prompt the user for a query\n",
    "input_query = str(input(\"Enter your query: \"))\n",
    "\n",
    "try:\n",
    "    # Execute the query using the QA chain\n",
    "    llm_response = qa_chain({\"query\": input_query})\n",
    "\n",
    "    # Print the response\n",
    "    print(llm_response['result'])\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Save the trained model to a pickle file\n",
    "with open(\"trained_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(base_model, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
